
# ğŸš• **Car detection pipeline**
Many companies are currently applying AI technology for vehicle recognition in buildings to better manage traffic. Our vehicle recognition application uses Modelmesh Kserve, TensorFlow Job distributed training, Kafka, and CI/CD technologies to effectively detect vehicle


# ğŸš€ **Challenge**
This project faced several challenges including ensuring data consistency and scalability during ingestion, managing resources and synchronization in distributed training, automating CI/CD pipelines, converting and deploying models efficiently, ensuring data privacy and security, optimizing performance, and handling the complexities of debugging and troubleshooting in a distributed system.

# ğŸ“• Table Of Contents
- ğŸŒŸ [System Architecture](#System-architecture)
- ğŸ“ [Repository Structure](#repository-structure)
- ğŸ” [How to Guide](#how-to-guide)

## ğŸŒŸ System Architecture
![Pipeline Serving](https://github.com/HungNguyenDev1511/Car-detection-serving-model/blob/refactor/images/diagram_pipe.gif)


## ğŸ“ Repository Structure
```
ğŸ“¦ 
â”œâ”€Â .env
â”œâ”€Â Jenkinsfile
â”œâ”€Â README.md
â”œâ”€Â api 
â”‚Â Â â”œâ”€Â README_serve.md
â”‚Â Â â”œâ”€Â triton_client.py
â”‚Â Â â””â”€Â upload_model_to_minio.py
â”œâ”€Â constants.py
â”œâ”€Â deployments // Serve the model and deploy the pod for training
â”‚Â Â â”œâ”€Â mwt.yaml
â”‚Â Â â”œâ”€Â triton-isvc.yaml
â”‚Â Â â””â”€Â triton-servingruntime.yaml
â”œâ”€Â distributed_training // logic for distributed training 
â”‚Â Â â”œâ”€Â Dockerfile
â”‚Â Â â”œâ”€Â README_distributed.md
â”‚Â Â â”œâ”€Â build.sh
â”‚Â Â â”œâ”€Â mwt.py
â”‚Â Â â”œâ”€Â nets
â”‚Â Â â”‚Â Â â””â”€Â nn.py
â”‚Â Â â”œâ”€Â test
â”‚Â Â â”‚Â Â â””â”€Â test.yaml
â”‚Â Â â”œâ”€Â utils
â”‚Â Â â”‚Â Â â”œâ”€Â config.py
â”‚Â Â â”‚Â Â â”œâ”€Â dataset.py
â”‚Â Â â”‚Â Â â””â”€Â image_utils.py
â”‚Â Â â””â”€Â weights
â”‚Â Â Â Â Â â””â”€Â model.h5
â”œâ”€Â docker-compose.yml
â”œâ”€Â images
â”œâ”€Â mlflow
â”‚Â Â â””â”€Â Dockerfile
â”œâ”€Â model_repo // model for serve
â”‚Â Â â””â”€Â yolov8n_car
â”‚Â Â Â Â Â â”œâ”€Â 1
â”‚Â Â Â Â Â â”‚Â Â â””â”€Â model.onnx
â”‚Â Â Â Â Â â””â”€Â config.pbtxt
â”œâ”€Â notebooks
â”‚Â Â â””â”€Â debug.ipynb
â”œâ”€Â requirements.txt
â””â”€Â streaming // ingest data for training
Â Â Â â”œâ”€Â Dockerfile
Â Â Â â”œâ”€Â README_streaming.md
Â Â Â â”œâ”€Â docker-compose.yml
Â Â Â â”œâ”€Â kafka_connector
Â Â Â â”‚Â Â â””â”€Â connect-timescaledb-sink.json 
Â Â Â â”œâ”€Â produce.py
Â Â Â â””â”€Â run.sh
```

## ğŸ” How to Guide

- Step 1: In the ingestion step, we gather data from the internet for training. Here are some advanced techniques for using Kafka in training:
1. Scalability: Kafka supports horizontal scaling, allowing you to handle increasing data volumes by adding more brokers to the Kafka cluster.
2. High Performance: Kafka can handle millions of events per second with low latency, thanks to its design of segment-based storage and efficient use of memory buffers.
3. Consistency: Kafka uses mechanisms for data replication and distribution, ensuring data consistency and recovery in case of failures.
``` shell
 cd streaming
 ```
 Read [Readme.md](https://github.com/HungNguyenDev1511/Car-detection-serving-model/blob/refactor/streaming/README_streaming.md) for this step
- Step 2: Training. To train the model for serving, here are some advanced techniques for distributed training:
1. Gradient Accumulation: Reducing synchronization frequency by accumulating gradients.
2. Mixed Precision Training: Using lower precision for faster computations and less memory usage.
3. Communication Optimization: Reducing communication overhead with techniques like Ring-AllReduce.
``` shell
 cd distributed_training
 ```
 Read [Readme.md](https://github.com/HungNguyenDev1511/Car-detection-serving-model/blob/refactor/distributed_training/README_distributed.md) for this step
- Step 3: Serving. Use the model trained in the previous step for inference. Here are some advanced techniques
1. Scalability: ModelMesh supports scaling of model serving infrastructure to handle varying loads and large volumes of requests.
2. Multi-Model Support: It can manage and serve multiple models simultaneously, allowing for a more flexible deployment strategy.
3. Efficient Resource Utilization: ModelMesh optimizes the use of resources by dynamically allocating them based on the demand for different models.
``` shell
 cd api
 ```
Read [Readme.md](https://github.com/HungNguyenDev1511/Car-detection-serving-model/blob/refactor/api/README_serve.md) for this step
