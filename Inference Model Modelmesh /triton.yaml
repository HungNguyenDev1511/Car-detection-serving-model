Warning: '--strict-model-config' has been deprecated! Please use '--disable-auto-complete-config' instead.
W0411 14:53:37.270231 1 pinned_memory_manager.cc:237] Unable to allocate pinned system memory, pinned memory pool will not be available: CUDA driver version is insufficient for CUDA runtime version
I0411 14:53:37.270376 1 cuda_memory_manager.cc:117] CUDA memory pool disabled
I0411 14:53:37.270901 1 server.cc:592] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0411 14:53:37.271108 1 server.cc:619] 
+---------+------+--------+
| Backend | Path | Config |
+---------+------+--------+
+---------+------+--------+

I0411 14:53:37.271214 1 server.cc:662] 
+-------+---------+--------+
| Model | Version | Status |
+-------+---------+--------+
+-------+---------+--------+

Error: Failed to initialize NVML
W0411 14:53:37.290945 1 metrics.cc:738] DCGM unable to start: DCGM initialization error
I0411 14:53:37.291359 1 metrics.cc:710] Collecting CPU metrics
I0411 14:53:37.291803 1 tritonserver.cc:2437] 
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                           |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                                          |
| server_version                   | 2.38.0                                                                                                                                                                                                          |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data parameters statistics trace logging |
| model_repository_path[0]         | /models/_triton_models                                                                                                                                                                                          |
| model_control_mode               | MODE_EXPLICIT                                                                                                                                                                                                   |
| strict_model_config              | 0                                                                                                                                                                                                               |
| rate_limit                       | OFF                                                                                                                                                                                                             |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                                       |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                             |
| strict_readiness                 | 0                                                                                                                                                                                                               |
| exit_timeout                     | 30                                                                                                                                                                                                              |
| cache_enabled                    | 0                                                                                                                                                                                                               |
+----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0411 14:53:37.295772 1 grpc_server.cc:2513] Started GRPCInferenceService at 0.0.0.0:8001
I0411 14:53:37.296341 1 http_server.cc:3620] Started HTTPService at 0.0.0.0:8000
I0411 14:53:37.338831 1 http_server.cc:187] Started Metrics Service at 0.0.0.0:8002
I0411 14:55:38.630161 1 model_lifecycle.cc:461] loading: onnx__isvc-0793e0df3c:1
I0411 14:55:38.753845 1 onnxruntime.cc:2514] TRITONBACKEND_Initialize: onnxruntime
I0411 14:55:38.753901 1 onnxruntime.cc:2524] Triton TRITONBACKEND API version: 1.16
I0411 14:55:38.753915 1 onnxruntime.cc:2530] 'onnxruntime' TRITONBACKEND API version: 1.16
I0411 14:55:38.753930 1 onnxruntime.cc:2560] backend configuration:
{"cmdline":{"auto-complete-config":"true","backend-directory":"/opt/tritonserver/backends","min-compute-capability":"6.000000","default-max-batch-size":"4"}}
I0411 14:55:38.821767 1 onnxruntime.cc:2625] TRITONBACKEND_ModelInitialize: onnx__isvc-0793e0df3c (version 1)
W0411 14:55:39.676660 1 onnxruntime.cc:813] autofilled max_batch_size to 4 for model 'onnx__isvc-0793e0df3c' since batching is supporrted but no max_batch_size is specified in model configuration. Must specify max_batch_size to utilize autofill with a larger max batch size
I0411 14:55:39.735806 1 onnxruntime.cc:2690] TRITONBACKEND_ModelInstanceInitialize: onnx__isvc-0793e0df3c_1 (CPU device 0)
I0411 14:55:39.736767 1 onnxruntime.cc:2690] TRITONBACKEND_ModelInstanceInitialize: onnx__isvc-0793e0df3c_0 (CPU device 0)
I0411 14:55:40.962850 1 model_lifecycle.cc:818] successfully loaded 'onnx__isvc-0793e0df3c'
